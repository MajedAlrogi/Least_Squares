{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as met\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.linalg as scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin we insert a constant one term so the bias will be subsumed into our weight vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/iris.csv') #data frame\n",
    "feature_names = df.keys() # Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width','species'],dtype='object')\n",
    "\n",
    "df.insert(0, 'bias', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we sort through the entries of our dataset by label and randomly split the data such that 40 of the samples are training ans the remaining 10 are added to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = list()\n",
    "s2 = list()\n",
    "\n",
    "\n",
    "for species in df['species'].unique():\n",
    "    train, test = train_test_split(df[df['species'] == species], test_size=0.2)\n",
    "    s1.append(train)\n",
    "    s2.append(test)\n",
    "\n",
    "trainDF = pd.concat(s1)\n",
    "testDF = pd.concat(s2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = trainDF.iloc[0:120,0:5].to_numpy()\n",
    "Y_train = trainDF.iloc[0:120,5].to_numpy()\n",
    "\n",
    "X_test = testDF.iloc[0:30,0:5].to_numpy()\n",
    "Y_test = testDF.iloc[0:30,5].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we make label vectors for our training data where the number 1 is assigned to the target label of our binary classifier and -1 is assigned to the other labels. We repeat the process for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_train = list()\n",
    "\n",
    "\n",
    "for species in df['species'].unique():\n",
    "    label_train = np.array([1 if item == species else -1 for item in Y_train])\n",
    "    list_train.append(label_train)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below functions take an array of array of  real numbers numbers and maps it to the string label corresponding to the highest real number. This makes comparison easier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping function to map numbers to strings\n",
    "def map_to_string(number):\n",
    "    mapping = {\n",
    "        0: 'Iris-setosa',\n",
    "        1: 'Iris-versicolor',\n",
    "        2: 'Iris-virginica',\n",
    "    }\n",
    "    return mapping.get(number, 'Unknown')\n",
    "\n",
    "def get_classification(data,weights):\n",
    "    guesses = np.argmax(data@(np.vstack(weights).T),axis=1)\n",
    "    string_vector = np.vectorize(map_to_string)(guesses)\n",
    "    return string_vector\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell we obtain the QR factorization of our training data and use it to solve for our ideal weights to minimize loss for each one of our binary classifiers. We then pass the weights for our 3 classifiers to the helper function to get our classifications. \n",
    "\n",
    "We then get the confusion matrix and observe results.\n",
    "\n",
    "It clearly classified all setosa flowers correctly but made more mistakes with versicolor and verginica. They were misclassified almost equally with 27 versicolor being classified correctly and 30 virginica being classified correctly.\n",
    "\n",
    "Error rate = 13.3%\n",
    "\n",
    "This means our model has preformed well on the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted        Iris-setosa  Iris-versicolor  Iris-virginica  All\n",
      "Actual                                                            \n",
      "Iris-setosa               40                0               0   40\n",
      "Iris-versicolor            0               29              11   40\n",
      "Iris-virginica             0                5              35   40\n",
      "All                       40               34              46  120\n",
      "Error rate is  0.13333333333333333\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "#QR composition\n",
    "Q, R = np.linalg.qr(X_train)\n",
    "\n",
    "weight_list = list()\n",
    "for label in list_train:\n",
    "    weight_list.append(scipy.solve_triangular(R,(Q.T@label))) #returns our weights\n",
    "training_classifications = get_classification(X_train,weight_list)\n",
    "df_confusion = pd.crosstab(Y_train, training_classifications, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(df_confusion)\n",
    "print(\"Error rate is \", np.sum(Y_train != training_classifications)/Y_train.size)\n",
    "print(R.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again the classifier predicted all setosa correctly. This could mean that setosa flowers are more distinctive in terms of these features to other flowers. The error rate was 5/30 which 16%. This is close to our training accuracy and is stil very good. This indicates that our model is not overfitting and is gereralizing towards unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted        Iris-setosa  Iris-versicolor  Iris-virginica  All\n",
      "Actual                                                            \n",
      "Iris-setosa               10                0               0   10\n",
      "Iris-versicolor            0                8               2   10\n",
      "Iris-virginica             0                3               7   10\n",
      "All                       10               11               9   30\n",
      "\n",
      "Error rate is  0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tst_classifications = get_classification(X_test,weight_list)\n",
    "df_confusion_test = pd.crosstab(Y_test, tst_classifications, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(df_confusion_test)\n",
    "print()\n",
    "print(\"Error rate is \", np.sum(Y_test != tst_classifications)/Y_test.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mathML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
